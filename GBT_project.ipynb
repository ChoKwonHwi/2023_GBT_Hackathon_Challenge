{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1a36039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "pd.set_option('display.max_columns', None)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39a2ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS': 50,\n",
    "    'LEARNING_RATE':1e-2,\n",
    "    'BATCH_SIZE':256,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f462182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4386c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a45c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['COMPONENT_ARBITRARY']#, 'YEAR']\n",
    "# Inference(실제 진단 환경)에 사용하는 컬럼\n",
    "test_stage_features = ['ANONYMOUS_1', 'ANONYMOUS_2', 'AG', 'CO', 'CR', 'CU', 'FE', 'H2O', 'MN', 'MO', 'NI', 'PQINDEX', 'TI', 'V', 'V40', 'ZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c4acd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['YEAR'], axis = 1)\n",
    "test = test.drop(['YEAR'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79b5d721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측이 있는 변수\n",
      "mis_val_bool\n",
      "False    34\n",
      "True     19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mis_val = train.isnull().sum()\n",
    "mis_val_bool = mis_val >= 1\n",
    "mis_val_df = pd.concat([mis_val, mis_val_bool], axis = 1)\n",
    "mis_val_df = mis_val_df.rename(columns = {0 : 'mis_val', 1 : 'mis_val_bool'})\n",
    "\n",
    "print(\"결측이 있는 변수\")\n",
    "print(mis_val_df['mis_val_bool'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f9416e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mis_val</th>\n",
       "      <th>mis_val_bool</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CD</th>\n",
       "      <td>1394</td>\n",
       "      <td>True</td>\n",
       "      <td>0.098900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FH2O</th>\n",
       "      <td>10205</td>\n",
       "      <td>True</td>\n",
       "      <td>0.724016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNOX</th>\n",
       "      <td>10205</td>\n",
       "      <td>True</td>\n",
       "      <td>0.724016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOPTIMETHGLY</th>\n",
       "      <td>10205</td>\n",
       "      <td>True</td>\n",
       "      <td>0.724016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOXID</th>\n",
       "      <td>10205</td>\n",
       "      <td>True</td>\n",
       "      <td>0.724016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSO4</th>\n",
       "      <td>10205</td>\n",
       "      <td>True</td>\n",
       "      <td>0.724016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTBN</th>\n",
       "      <td>10205</td>\n",
       "      <td>True</td>\n",
       "      <td>0.724016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUEL</th>\n",
       "      <td>10205</td>\n",
       "      <td>True</td>\n",
       "      <td>0.724016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>2299</td>\n",
       "      <td>True</td>\n",
       "      <td>0.163107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOOTPERCENTAGE</th>\n",
       "      <td>10205</td>\n",
       "      <td>True</td>\n",
       "      <td>0.724016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U100</th>\n",
       "      <td>11779</td>\n",
       "      <td>True</td>\n",
       "      <td>0.835686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U75</th>\n",
       "      <td>11779</td>\n",
       "      <td>True</td>\n",
       "      <td>0.835686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U50</th>\n",
       "      <td>11779</td>\n",
       "      <td>True</td>\n",
       "      <td>0.835686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U25</th>\n",
       "      <td>11779</td>\n",
       "      <td>True</td>\n",
       "      <td>0.835686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U20</th>\n",
       "      <td>11779</td>\n",
       "      <td>True</td>\n",
       "      <td>0.835686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U14</th>\n",
       "      <td>11977</td>\n",
       "      <td>True</td>\n",
       "      <td>0.849734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U6</th>\n",
       "      <td>11977</td>\n",
       "      <td>True</td>\n",
       "      <td>0.849734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U4</th>\n",
       "      <td>11977</td>\n",
       "      <td>True</td>\n",
       "      <td>0.849734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V100</th>\n",
       "      <td>10371</td>\n",
       "      <td>True</td>\n",
       "      <td>0.735793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mis_val  mis_val_bool     ratio\n",
       "CD                 1394          True  0.098900\n",
       "FH2O              10205          True  0.724016\n",
       "FNOX              10205          True  0.724016\n",
       "FOPTIMETHGLY      10205          True  0.724016\n",
       "FOXID             10205          True  0.724016\n",
       "FSO4              10205          True  0.724016\n",
       "FTBN              10205          True  0.724016\n",
       "FUEL              10205          True  0.724016\n",
       "K                  2299          True  0.163107\n",
       "SOOTPERCENTAGE    10205          True  0.724016\n",
       "U100              11779          True  0.835686\n",
       "U75               11779          True  0.835686\n",
       "U50               11779          True  0.835686\n",
       "U25               11779          True  0.835686\n",
       "U20               11779          True  0.835686\n",
       "U14               11977          True  0.849734\n",
       "U6                11977          True  0.849734\n",
       "U4                11977          True  0.849734\n",
       "V100              10371          True  0.735793"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_val_data = mis_val_df.loc[mis_val_df['mis_val_bool'] == True, :]\n",
    "mis_val_data['ratio'] = mis_val_data['mis_val'] / 14095\n",
    "mis_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1e5442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14095, 35)\n",
      "Index(['COMPONENT_ARBITRARY', 'ANONYMOUS_1', 'SAMPLE_TRANSFER_DAY',\n",
      "       'ANONYMOUS_2', 'AG', 'AL', 'B', 'BA', 'BE', 'CA', 'CO', 'CR', 'CU',\n",
      "       'FE', 'H2O', 'LI', 'MG', 'MN', 'MO', 'NA', 'NI', 'P', 'PB', 'PQINDEX',\n",
      "       'S', 'SB', 'SI', 'SN', 'TI', 'V', 'V40', 'ZN', 'K', 'CD', 'Y_LABEL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "notnull_columns = train.loc[:, train.notnull().sum(axis = 0) == 14095].columns\n",
    "notnull_columns = notnull_columns[1 :]\n",
    "notnull_columns = list(notnull_columns)\n",
    "\n",
    "select_columns = notnull_columns[: 32] + ['K', 'CD'] + notnull_columns[32 :]\n",
    "train = train.loc[:, select_columns]\n",
    "print(train.shape)\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d84af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2690e318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>SAMPLE_TRANSFER_DAY</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>AL</th>\n",
       "      <th>B</th>\n",
       "      <th>BA</th>\n",
       "      <th>BE</th>\n",
       "      <th>CA</th>\n",
       "      <th>CO</th>\n",
       "      <th>CR</th>\n",
       "      <th>CU</th>\n",
       "      <th>FE</th>\n",
       "      <th>H2O</th>\n",
       "      <th>LI</th>\n",
       "      <th>MG</th>\n",
       "      <th>MN</th>\n",
       "      <th>MO</th>\n",
       "      <th>NA</th>\n",
       "      <th>NI</th>\n",
       "      <th>P</th>\n",
       "      <th>PB</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>S</th>\n",
       "      <th>SB</th>\n",
       "      <th>SI</th>\n",
       "      <th>SN</th>\n",
       "      <th>TI</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "      <th>K</th>\n",
       "      <th>CD</th>\n",
       "      <th>COMPONENT1</th>\n",
       "      <th>COMPONENT2</th>\n",
       "      <th>COMPONENT3</th>\n",
       "      <th>COMPONENT4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>-0.069099</td>\n",
       "      <td>0.116588</td>\n",
       "      <td>-0.337936</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.101686</td>\n",
       "      <td>0.678118</td>\n",
       "      <td>-0.228777</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>1.220967</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.113358</td>\n",
       "      <td>-0.261477</td>\n",
       "      <td>-0.314001</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>-0.270107</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>-0.398820</td>\n",
       "      <td>-0.208246</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>-1.043886</td>\n",
       "      <td>-0.154584</td>\n",
       "      <td>-0.263715</td>\n",
       "      <td>-1.105093</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.175244</td>\n",
       "      <td>0.783891</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>-0.755923</td>\n",
       "      <td>-0.284106</td>\n",
       "      <td>-0.198039</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>-0.413153</td>\n",
       "      <td>-0.225434</td>\n",
       "      <td>0.293370</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.125019</td>\n",
       "      <td>-0.549336</td>\n",
       "      <td>0.102931</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>-0.780446</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.043191</td>\n",
       "      <td>-0.214906</td>\n",
       "      <td>-0.283485</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>0.32653</td>\n",
       "      <td>-0.182968</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>1.918859</td>\n",
       "      <td>-0.208246</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>0.066496</td>\n",
       "      <td>-0.154584</td>\n",
       "      <td>-0.259153</td>\n",
       "      <td>-0.625465</td>\n",
       "      <td>0.617902</td>\n",
       "      <td>-0.131071</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>0.083483</td>\n",
       "      <td>1.384500</td>\n",
       "      <td>0.750812</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>-0.413435</td>\n",
       "      <td>-0.396445</td>\n",
       "      <td>-0.013264</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.113352</td>\n",
       "      <td>0.127214</td>\n",
       "      <td>-0.228777</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>1.283110</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.113358</td>\n",
       "      <td>-0.253715</td>\n",
       "      <td>-0.314001</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>-0.148112</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>0.168094</td>\n",
       "      <td>-0.208246</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>-0.006345</td>\n",
       "      <td>-0.061985</td>\n",
       "      <td>-0.266974</td>\n",
       "      <td>-1.003650</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.150703</td>\n",
       "      <td>-0.332775</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>-0.114024</td>\n",
       "      <td>0.801991</td>\n",
       "      <td>-0.008269</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12302</th>\n",
       "      <td>-0.003954</td>\n",
       "      <td>-0.567456</td>\n",
       "      <td>-0.337936</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.125019</td>\n",
       "      <td>-0.597661</td>\n",
       "      <td>-0.228777</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>-0.906083</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.008108</td>\n",
       "      <td>-0.253715</td>\n",
       "      <td>1.540321</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>0.32653</td>\n",
       "      <td>-0.182968</td>\n",
       "      <td>0.788237</td>\n",
       "      <td>-0.365472</td>\n",
       "      <td>-0.155563</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>0.913940</td>\n",
       "      <td>-0.154584</td>\n",
       "      <td>-0.058417</td>\n",
       "      <td>1.070625</td>\n",
       "      <td>1.019230</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>-0.332775</td>\n",
       "      <td>5.119013</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>0.891288</td>\n",
       "      <td>-0.998150</td>\n",
       "      <td>-0.198039</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>-0.519754</td>\n",
       "      <td>-0.225434</td>\n",
       "      <td>-0.337936</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.055021</td>\n",
       "      <td>-0.587996</td>\n",
       "      <td>0.434638</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>-0.905408</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.078274</td>\n",
       "      <td>-0.230430</td>\n",
       "      <td>-0.290665</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>3.337463</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>2.185642</td>\n",
       "      <td>-0.050197</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>-0.036547</td>\n",
       "      <td>0.030615</td>\n",
       "      <td>-0.265019</td>\n",
       "      <td>-0.834578</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.135979</td>\n",
       "      <td>0.783891</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>0.231613</td>\n",
       "      <td>0.873395</td>\n",
       "      <td>0.118245</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10754</th>\n",
       "      <td>0.061190</td>\n",
       "      <td>-0.225434</td>\n",
       "      <td>-0.337936</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.113352</td>\n",
       "      <td>3.683932</td>\n",
       "      <td>-0.228777</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>1.568833</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.113358</td>\n",
       "      <td>-0.261477</td>\n",
       "      <td>-0.306821</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>-0.174254</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>3.819689</td>\n",
       "      <td>-0.050197</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>0.499989</td>\n",
       "      <td>-0.154584</td>\n",
       "      <td>-0.268929</td>\n",
       "      <td>-0.728626</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.145795</td>\n",
       "      <td>-0.332775</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>0.049907</td>\n",
       "      <td>1.497244</td>\n",
       "      <td>-0.008269</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11793</th>\n",
       "      <td>-0.406103</td>\n",
       "      <td>-0.310939</td>\n",
       "      <td>-0.337936</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.113352</td>\n",
       "      <td>1.866913</td>\n",
       "      <td>-0.228777</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>1.208133</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.043191</td>\n",
       "      <td>-0.245953</td>\n",
       "      <td>-0.290665</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>-0.182968</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>3.552906</td>\n",
       "      <td>-0.102880</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>0.384510</td>\n",
       "      <td>0.123214</td>\n",
       "      <td>-0.256546</td>\n",
       "      <td>-0.780367</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.145795</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>0.032131</td>\n",
       "      <td>1.499123</td>\n",
       "      <td>-0.008269</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10052</th>\n",
       "      <td>0.304003</td>\n",
       "      <td>-0.396445</td>\n",
       "      <td>-0.337936</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.148351</td>\n",
       "      <td>-0.549336</td>\n",
       "      <td>-0.228777</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>-0.911487</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>0.026975</td>\n",
       "      <td>0.848467</td>\n",
       "      <td>0.034245</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>-0.261393</td>\n",
       "      <td>0.020479</td>\n",
       "      <td>-0.398820</td>\n",
       "      <td>-0.050197</td>\n",
       "      <td>1.391556</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>-0.154584</td>\n",
       "      <td>-0.193979</td>\n",
       "      <td>1.860381</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.150703</td>\n",
       "      <td>-0.332775</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>0.707606</td>\n",
       "      <td>-0.868494</td>\n",
       "      <td>-0.134782</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805</th>\n",
       "      <td>-0.553595</td>\n",
       "      <td>-0.396445</td>\n",
       "      <td>-0.007853</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.125019</td>\n",
       "      <td>-0.559001</td>\n",
       "      <td>0.766346</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>-0.178604</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.078274</td>\n",
       "      <td>0.064521</td>\n",
       "      <td>-0.267329</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>7.938423</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>0.418203</td>\n",
       "      <td>-0.155563</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>0.285019</td>\n",
       "      <td>-0.154584</td>\n",
       "      <td>-0.265671</td>\n",
       "      <td>-0.920885</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.121254</td>\n",
       "      <td>0.783891</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>-0.416210</td>\n",
       "      <td>1.207868</td>\n",
       "      <td>0.181501</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12169</th>\n",
       "      <td>0.428088</td>\n",
       "      <td>3.109281</td>\n",
       "      <td>0.293370</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.101686</td>\n",
       "      <td>0.504148</td>\n",
       "      <td>0.102931</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>-0.862178</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.113358</td>\n",
       "      <td>-0.245953</td>\n",
       "      <td>-0.294255</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>-0.139398</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>-0.398820</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>0.270807</td>\n",
       "      <td>0.030615</td>\n",
       "      <td>-0.265671</td>\n",
       "      <td>-0.107299</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.150703</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>-0.159451</td>\n",
       "      <td>1.209747</td>\n",
       "      <td>0.244758</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11276 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ANONYMOUS_1  SAMPLE_TRANSFER_DAY  ANONYMOUS_2        AG        AL  \\\n",
       "6224     -0.069099             0.116588    -0.337936 -0.151896 -0.101686   \n",
       "1786     -0.413153            -0.225434     0.293370 -0.151896 -0.125019   \n",
       "2999     -0.413435            -0.396445    -0.013264 -0.151896 -0.113352   \n",
       "12302    -0.003954            -0.567456    -0.337936 -0.151896 -0.125019   \n",
       "8063     -0.519754            -0.225434    -0.337936 -0.151896 -0.055021   \n",
       "...            ...                  ...          ...       ...       ...   \n",
       "10754     0.061190            -0.225434    -0.337936 -0.151896 -0.113352   \n",
       "11793    -0.406103            -0.310939    -0.337936 -0.151896 -0.113352   \n",
       "10052     0.304003            -0.396445    -0.337936 -0.151896 -0.148351   \n",
       "11805    -0.553595            -0.396445    -0.007853 -0.151896 -0.125019   \n",
       "12169     0.428088             3.109281     0.293370 -0.151896 -0.101686   \n",
       "\n",
       "              B        BA        BE        CA        CO        CR        CU  \\\n",
       "6224   0.678118 -0.228777 -0.042583  1.220967 -0.087612 -0.113358 -0.261477   \n",
       "1786  -0.549336  0.102931 -0.042583 -0.780446 -0.087612 -0.043191 -0.214906   \n",
       "2999   0.127214 -0.228777 -0.042583  1.283110 -0.087612 -0.113358 -0.253715   \n",
       "12302 -0.597661 -0.228777 -0.042583 -0.906083 -0.087612 -0.008108 -0.253715   \n",
       "8063  -0.587996  0.434638 -0.042583 -0.905408 -0.087612 -0.078274 -0.230430   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10754  3.683932 -0.228777 -0.042583  1.568833 -0.087612 -0.113358 -0.261477   \n",
       "11793  1.866913 -0.228777 -0.042583  1.208133 -0.087612 -0.043191 -0.245953   \n",
       "10052 -0.549336 -0.228777 -0.042583 -0.911487 -0.087612  0.026975  0.848467   \n",
       "11805 -0.559001  0.766346 -0.042583 -0.178604 -0.087612 -0.078274  0.064521   \n",
       "12169  0.504148  0.102931 -0.042583 -0.862178 -0.087612 -0.113358 -0.245953   \n",
       "\n",
       "             FE       H2O       LI        MG        MN        MO        NA  \\\n",
       "6224  -0.314001 -0.044504 -0.10941 -0.270107 -0.235440 -0.398820 -0.208246   \n",
       "1786  -0.283485 -0.044504  0.32653 -0.182968 -0.235440  1.918859 -0.208246   \n",
       "2999  -0.314001 -0.044504 -0.10941 -0.148112 -0.235440  0.168094 -0.208246   \n",
       "12302  1.540321 -0.044504  0.32653 -0.182968  0.788237 -0.365472 -0.155563   \n",
       "8063  -0.290665 -0.044504 -0.10941  3.337463 -0.235440  2.185642 -0.050197   \n",
       "...         ...       ...      ...       ...       ...       ...       ...   \n",
       "10754 -0.306821 -0.044504 -0.10941 -0.174254 -0.235440  3.819689 -0.050197   \n",
       "11793 -0.290665 -0.044504 -0.10941 -0.182968 -0.235440  3.552906 -0.102880   \n",
       "10052  0.034245 -0.044504 -0.10941 -0.261393  0.020479 -0.398820 -0.050197   \n",
       "11805 -0.267329 -0.044504 -0.10941  7.938423 -0.235440  0.418203 -0.155563   \n",
       "12169 -0.294255 -0.044504 -0.10941 -0.139398 -0.235440 -0.398820  0.002486   \n",
       "\n",
       "             NI         P        PB   PQINDEX         S        SB        SI  \\\n",
       "6224  -0.189712 -1.043886 -0.154584 -0.263715 -1.105093 -0.184755 -0.175244   \n",
       "1786  -0.189712  0.066496 -0.154584 -0.259153 -0.625465  0.617902 -0.131071   \n",
       "2999  -0.189712 -0.006345 -0.061985 -0.266974 -1.003650 -0.184755 -0.150703   \n",
       "12302 -0.189712  0.913940 -0.154584 -0.058417  1.070625  1.019230 -0.072173   \n",
       "8063  -0.189712 -0.036547  0.030615 -0.265019 -0.834578 -0.184755 -0.135979   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10754 -0.189712  0.499989 -0.154584 -0.268929 -0.728626 -0.184755 -0.145795   \n",
       "11793 -0.189712  0.384510  0.123214 -0.256546 -0.780367 -0.184755 -0.145795   \n",
       "10052  1.391556  0.029187 -0.154584 -0.193979  1.860381 -0.184755 -0.150703   \n",
       "11805 -0.189712  0.285019 -0.154584 -0.265671 -0.920885 -0.184755 -0.121254   \n",
       "12169 -0.189712  0.270807  0.030615 -0.265671 -0.107299 -0.184755 -0.150703   \n",
       "\n",
       "             SN        TI         V       V40        ZN         K       CD  \\\n",
       "6224   0.783891 -0.097491 -0.113111 -0.755923 -0.284106 -0.198039 -0.06603   \n",
       "1786   0.039447 -0.097491 -0.113111  0.083483  1.384500  0.750812 -0.06603   \n",
       "2999  -0.332775 -0.097491 -0.113111 -0.114024  0.801991 -0.008269 -0.06603   \n",
       "12302 -0.332775  5.119013 -0.113111  0.891288 -0.998150 -0.198039 -0.06603   \n",
       "8063   0.783891 -0.097491 -0.113111  0.231613  0.873395  0.118245 -0.06603   \n",
       "...         ...       ...       ...       ...       ...       ...      ...   \n",
       "10754 -0.332775 -0.097491 -0.113111  0.049907  1.497244 -0.008269 -0.06603   \n",
       "11793  0.039447 -0.097491 -0.113111  0.032131  1.499123 -0.008269 -0.06603   \n",
       "10052 -0.332775 -0.097491 -0.113111  0.707606 -0.868494 -0.134782 -0.06603   \n",
       "11805  0.783891 -0.097491 -0.113111 -0.416210  1.207868  0.181501 -0.06603   \n",
       "12169  0.039447 -0.097491 -0.113111 -0.159451  1.209747  0.244758 -0.06603   \n",
       "\n",
       "       COMPONENT1  COMPONENT2  COMPONENT3  COMPONENT4  \n",
       "6224            0           1           0           0  \n",
       "1786            1           0           0           0  \n",
       "2999            1           0           0           0  \n",
       "12302           0           0           1           0  \n",
       "8063            1           0           0           0  \n",
       "...           ...         ...         ...         ...  \n",
       "10754           1           0           0           0  \n",
       "11793           1           0           0           0  \n",
       "10052           0           0           1           0  \n",
       "11805           1           0           0           0  \n",
       "12169           1           0           0           0  \n",
       "\n",
       "[11276 rows x 37 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0e00edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_col = []\n",
    "for c in categorical_features:\n",
    "    df = pd.get_dummies(train[c])\n",
    "    train[df.columns] = df\n",
    "    train = train.drop(c, axis=1)\n",
    "    df = pd.get_dummies(test[c])\n",
    "    test[df.columns] = df\n",
    "    test = test.drop(c, axis=1)\n",
    "    dummies_col.extend(df.columns)\n",
    "test_stage_features.extend(dummies_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c31ced0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X = train.drop(['ID', 'Y_LABEL'], axis = 1)\n",
    "#all_X = train.drop(['Y_LABEL'], axis = 1)\n",
    "all_y = train['Y_LABEL']\n",
    "\n",
    "test = test.drop(['ID'], axis = 1)\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(all_X, all_y, test_size=0.2, random_state=CFG['SEED'], stratify=all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d63fe301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(value):\n",
    "    return value.values.reshape(-1, 1)\n",
    "\n",
    "for col in train_X.columns:\n",
    "    if col not in dummies_col:\n",
    "        scaler = StandardScaler()\n",
    "        train_X[col] = scaler.fit_transform(get_values(train_X[col]))\n",
    "        val_X[col] = scaler.transform(get_values(val_X[col]))\n",
    "        if col in test.columns:\n",
    "            test[col] = scaler.transform(get_values(test[col]))\n",
    "            \n",
    "le = LabelEncoder()\n",
    "for col in dummies_col:    \n",
    "    train_X[col] = le.fit_transform(train_X[col])\n",
    "    val_X[col] = le.transform(val_X[col])\n",
    "    if col in test.columns:\n",
    "        test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff45755c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "x = sns.heatmap(train.corr(), cmap = 'Blues', linewidths = '0.1',annot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "9445305b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>SAMPLE_TRANSFER_DAY</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>AL</th>\n",
       "      <th>B</th>\n",
       "      <th>BA</th>\n",
       "      <th>BE</th>\n",
       "      <th>CA</th>\n",
       "      <th>CO</th>\n",
       "      <th>CR</th>\n",
       "      <th>CU</th>\n",
       "      <th>FE</th>\n",
       "      <th>H2O</th>\n",
       "      <th>LI</th>\n",
       "      <th>MG</th>\n",
       "      <th>MN</th>\n",
       "      <th>MO</th>\n",
       "      <th>NA</th>\n",
       "      <th>NI</th>\n",
       "      <th>P</th>\n",
       "      <th>PB</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>S</th>\n",
       "      <th>SB</th>\n",
       "      <th>SI</th>\n",
       "      <th>SN</th>\n",
       "      <th>TI</th>\n",
       "      <th>V</th>\n",
       "      <th>V40</th>\n",
       "      <th>K</th>\n",
       "      <th>CD</th>\n",
       "      <th>ZN</th>\n",
       "      <th>COMPONENT1</th>\n",
       "      <th>COMPONENT2</th>\n",
       "      <th>COMPONENT3</th>\n",
       "      <th>COMPONENT4</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMPLE_TRANSFER_DAY</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H2O</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LI</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NI</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PB</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PQINDEX</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SB</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TI</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMPONENT1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMPONENT2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMPONENT3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMPONENT4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ANONYMOUS_1  SAMPLE_TRANSFER_DAY  ANONYMOUS_2   AG   AL  \\\n",
       "ANONYMOUS_1                  1.0                  NaN          NaN  NaN  NaN   \n",
       "SAMPLE_TRANSFER_DAY          NaN                  1.0          NaN  NaN  NaN   \n",
       "ANONYMOUS_2                  NaN                  NaN          1.0  NaN  NaN   \n",
       "AG                           NaN                  NaN          NaN  1.0  NaN   \n",
       "AL                           NaN                  NaN          NaN  NaN  1.0   \n",
       "B                            NaN                  NaN          NaN  NaN  NaN   \n",
       "BA                           NaN                  NaN          NaN  NaN  NaN   \n",
       "BE                           NaN                  NaN          NaN  NaN  NaN   \n",
       "CA                           NaN                  NaN          NaN  NaN  NaN   \n",
       "CO                           NaN                  NaN          NaN  NaN  NaN   \n",
       "CR                           NaN                  NaN          NaN  NaN  NaN   \n",
       "CU                           NaN                  NaN          NaN  NaN  NaN   \n",
       "FE                           NaN                  NaN          NaN  NaN  NaN   \n",
       "H2O                          NaN                  NaN          NaN  NaN  NaN   \n",
       "LI                           NaN                  NaN          NaN  NaN  NaN   \n",
       "MG                           NaN                  NaN          NaN  NaN  NaN   \n",
       "MN                           NaN                  NaN          NaN  NaN  NaN   \n",
       "MO                           NaN                  NaN          NaN  NaN  NaN   \n",
       "NA                           NaN                  NaN          NaN  NaN  NaN   \n",
       "NI                           NaN                  NaN          NaN  NaN  NaN   \n",
       "P                            NaN                  NaN          NaN  NaN  NaN   \n",
       "PB                           NaN                  NaN          NaN  NaN  NaN   \n",
       "PQINDEX                      NaN                  NaN          NaN  NaN  NaN   \n",
       "S                            NaN                  NaN          NaN  NaN  NaN   \n",
       "SB                           NaN                  NaN          NaN  NaN  NaN   \n",
       "SI                           NaN                  NaN          NaN  NaN  NaN   \n",
       "SN                           NaN                  NaN          NaN  NaN  NaN   \n",
       "TI                           NaN                  NaN          NaN  NaN  NaN   \n",
       "V                            NaN                  NaN          NaN  NaN  NaN   \n",
       "V40                          NaN                  NaN          NaN  NaN  NaN   \n",
       "K                            NaN                  NaN          NaN  NaN  NaN   \n",
       "CD                           NaN                  NaN          NaN  NaN  NaN   \n",
       "ZN                           NaN                  NaN          NaN  NaN  NaN   \n",
       "COMPONENT1                   NaN                  NaN          NaN  NaN  NaN   \n",
       "COMPONENT2                   NaN                  NaN          NaN  NaN  NaN   \n",
       "COMPONENT3                   NaN                  NaN          NaN  NaN  NaN   \n",
       "COMPONENT4                   NaN                  NaN          NaN  NaN  NaN   \n",
       "2007                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2008                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2009                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2010                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2011                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2012                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2013                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2014                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2015                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2016                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2017                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2018                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2019                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2020                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2021                         NaN                  NaN          NaN  NaN  NaN   \n",
       "2022                         NaN                  NaN          NaN  NaN  NaN   \n",
       "\n",
       "                       B   BA   BE   CA   CO   CR   CU   FE  H2O   LI   MG  \\\n",
       "ANONYMOUS_1          NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "SAMPLE_TRANSFER_DAY  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "ANONYMOUS_2          NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "AG                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "AL                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "B                    1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "BA                   NaN  1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "BE                   NaN  NaN  1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "CA                   NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "CO                   NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "CR                   NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN  NaN   \n",
       "CU                   NaN  NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN   \n",
       "FE                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN   \n",
       "H2O                  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN   \n",
       "LI                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  NaN   \n",
       "MG                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0   \n",
       "MN                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "MO                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "NA                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "NI                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "P                    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "PB                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "PQINDEX              NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "S                    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "SB                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "SI                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "SN                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "TI                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "V                    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "V40                  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "K                    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "CD                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "ZN                   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "COMPONENT1           NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "COMPONENT2           NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "COMPONENT3           NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "COMPONENT4           NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2007                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2008                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2009                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2010                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2011                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2012                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2013                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2014                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2015                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2016                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2017                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2018                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2019                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2020                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2021                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2022                 NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "                      MN   MO   NA   NI    P   PB  PQINDEX    S   SB   SI  \\\n",
       "ANONYMOUS_1          NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "SAMPLE_TRANSFER_DAY  NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "ANONYMOUS_2          NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "AG                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "AL                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "B                    NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "BA                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "BE                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "CA                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "CO                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "CR                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "CU                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "FE                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "H2O                  NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "LI                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "MG                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "MN                   1.0  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "MO                   NaN  1.0  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "NA                   NaN  NaN  1.0  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "NI                   NaN  NaN  NaN  1.0  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "P                    NaN  NaN  NaN  NaN  1.0  NaN      NaN  NaN  NaN  NaN   \n",
       "PB                   NaN  NaN  NaN  NaN  NaN  1.0      NaN  NaN  NaN  NaN   \n",
       "PQINDEX              NaN  NaN  NaN  NaN  NaN  NaN      1.0  NaN  NaN  NaN   \n",
       "S                    NaN  NaN  NaN  NaN  NaN  NaN      NaN  1.0  NaN  NaN   \n",
       "SB                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  1.0  NaN   \n",
       "SI                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  1.0   \n",
       "SN                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "TI                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "V                    NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "V40                  NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "K                    NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "CD                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "ZN                   NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "COMPONENT1           NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "COMPONENT2           NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "COMPONENT3           NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "COMPONENT4           NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2007                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2008                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2009                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2010                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2011                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2012                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2013                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2014                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2015                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2016                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2017                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2018                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2019                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2020                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2021                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "2022                 NaN  NaN  NaN  NaN  NaN  NaN      NaN  NaN  NaN  NaN   \n",
       "\n",
       "                      SN   TI    V  V40    K   CD   ZN  COMPONENT1  \\\n",
       "ANONYMOUS_1          NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "SAMPLE_TRANSFER_DAY  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "ANONYMOUS_2          NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "AG                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "AL                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "B                    NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "BA                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "BE                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "CA                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "CO                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "CR                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "CU                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "FE                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "H2O                  NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "LI                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "MG                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "MN                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "MO                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "NA                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "NI                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "P                    NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "PB                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "PQINDEX              NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "S                    NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "SB                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "SI                   NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "SN                   1.0  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "TI                   NaN  1.0  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "V                    NaN  NaN  1.0  NaN  NaN  NaN  NaN         NaN   \n",
       "V40                  NaN  NaN  NaN  1.0  NaN  NaN  NaN         NaN   \n",
       "K                    NaN  NaN  NaN  NaN  1.0  NaN  NaN         NaN   \n",
       "CD                   NaN  NaN  NaN  NaN  NaN  1.0  NaN         NaN   \n",
       "ZN                   NaN  NaN  NaN  NaN  NaN  NaN  1.0         NaN   \n",
       "COMPONENT1           NaN  NaN  NaN  NaN  NaN  NaN  NaN         1.0   \n",
       "COMPONENT2           NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "COMPONENT3           NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "COMPONENT4           NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2007                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2008                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2009                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2010                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2011                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2012                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2013                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2014                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2015                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2016                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2017                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2018                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2019                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2020                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2021                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "2022                 NaN  NaN  NaN  NaN  NaN  NaN  NaN         NaN   \n",
       "\n",
       "                     COMPONENT2  COMPONENT3  COMPONENT4  2007  2008  2009  \\\n",
       "ANONYMOUS_1                 NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "SAMPLE_TRANSFER_DAY         NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "ANONYMOUS_2                 NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "AG                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "AL                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "B                           NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "BA                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "BE                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "CA                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "CO                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "CR                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "CU                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "FE                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "H2O                         NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "LI                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "MG                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "MN                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "MO                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "NA                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "NI                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "P                           NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "PB                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "PQINDEX                     NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "S                           NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "SB                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "SI                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "SN                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "TI                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "V                           NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "V40                         NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "K                           NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "CD                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "ZN                          NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "COMPONENT1                  NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "COMPONENT2                  1.0         NaN         NaN   NaN   NaN   NaN   \n",
       "COMPONENT3                  NaN         1.0         NaN   NaN   NaN   NaN   \n",
       "COMPONENT4                  NaN         NaN         1.0   NaN   NaN   NaN   \n",
       "2007                        NaN         NaN         NaN   1.0   NaN   NaN   \n",
       "2008                        NaN         NaN         NaN   NaN   1.0   NaN   \n",
       "2009                        NaN         NaN         NaN   NaN   NaN   1.0   \n",
       "2010                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "2011                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "2012                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "2013                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "2014                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "2015                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "2016                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "2017                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "2018                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "2019                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "2020                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "2021                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "2022                        NaN         NaN         NaN   NaN   NaN   NaN   \n",
       "\n",
       "                     2010  2011  2012  2013  2014  2015  2016  2017  2018  \\\n",
       "ANONYMOUS_1           NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "SAMPLE_TRANSFER_DAY   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "ANONYMOUS_2           NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "AG                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "AL                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "B                     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "BA                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "BE                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "CA                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "CO                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "CR                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "CU                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "FE                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "H2O                   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "LI                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "MG                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "MN                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "MO                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "NA                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "NI                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "P                     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "PB                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "PQINDEX               NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "S                     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "SB                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "SI                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "SN                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "TI                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "V                     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "V40                   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "K                     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "CD                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "ZN                    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "COMPONENT1            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "COMPONENT2            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "COMPONENT3            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "COMPONENT4            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2007                  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2008                  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2009                  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2010                  1.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2011                  NaN   1.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2012                  NaN   NaN   1.0   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2013                  NaN   NaN   NaN   1.0   NaN   NaN   NaN   NaN   NaN   \n",
       "2014                  NaN   NaN   NaN   NaN   1.0   NaN   NaN   NaN   NaN   \n",
       "2015                  NaN   NaN   NaN   NaN   NaN   1.0   NaN   NaN   NaN   \n",
       "2016                  NaN   NaN   NaN   NaN   NaN   NaN   1.0   NaN   NaN   \n",
       "2017                  NaN   NaN   NaN   NaN   NaN   NaN   NaN   1.0   NaN   \n",
       "2018                  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   1.0   \n",
       "2019                  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2020                  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2021                  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2022                  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "                     2019  2020  2021  2022  \n",
       "ANONYMOUS_1           NaN   NaN   NaN   NaN  \n",
       "SAMPLE_TRANSFER_DAY   NaN   NaN   NaN   NaN  \n",
       "ANONYMOUS_2           NaN   NaN   NaN   NaN  \n",
       "AG                    NaN   NaN   NaN   NaN  \n",
       "AL                    NaN   NaN   NaN   NaN  \n",
       "B                     NaN   NaN   NaN   NaN  \n",
       "BA                    NaN   NaN   NaN   NaN  \n",
       "BE                    NaN   NaN   NaN   NaN  \n",
       "CA                    NaN   NaN   NaN   NaN  \n",
       "CO                    NaN   NaN   NaN   NaN  \n",
       "CR                    NaN   NaN   NaN   NaN  \n",
       "CU                    NaN   NaN   NaN   NaN  \n",
       "FE                    NaN   NaN   NaN   NaN  \n",
       "H2O                   NaN   NaN   NaN   NaN  \n",
       "LI                    NaN   NaN   NaN   NaN  \n",
       "MG                    NaN   NaN   NaN   NaN  \n",
       "MN                    NaN   NaN   NaN   NaN  \n",
       "MO                    NaN   NaN   NaN   NaN  \n",
       "NA                    NaN   NaN   NaN   NaN  \n",
       "NI                    NaN   NaN   NaN   NaN  \n",
       "P                     NaN   NaN   NaN   NaN  \n",
       "PB                    NaN   NaN   NaN   NaN  \n",
       "PQINDEX               NaN   NaN   NaN   NaN  \n",
       "S                     NaN   NaN   NaN   NaN  \n",
       "SB                    NaN   NaN   NaN   NaN  \n",
       "SI                    NaN   NaN   NaN   NaN  \n",
       "SN                    NaN   NaN   NaN   NaN  \n",
       "TI                    NaN   NaN   NaN   NaN  \n",
       "V                     NaN   NaN   NaN   NaN  \n",
       "V40                   NaN   NaN   NaN   NaN  \n",
       "K                     NaN   NaN   NaN   NaN  \n",
       "CD                    NaN   NaN   NaN   NaN  \n",
       "ZN                    NaN   NaN   NaN   NaN  \n",
       "COMPONENT1            NaN   NaN   NaN   NaN  \n",
       "COMPONENT2            NaN   NaN   NaN   NaN  \n",
       "COMPONENT3            NaN   NaN   NaN   NaN  \n",
       "COMPONENT4            NaN   NaN   NaN   NaN  \n",
       "2007                  NaN   NaN   NaN   NaN  \n",
       "2008                  NaN   NaN   NaN   NaN  \n",
       "2009                  NaN   NaN   NaN   NaN  \n",
       "2010                  NaN   NaN   NaN   NaN  \n",
       "2011                  NaN   NaN   NaN   NaN  \n",
       "2012                  NaN   NaN   NaN   NaN  \n",
       "2013                  NaN   NaN   NaN   NaN  \n",
       "2014                  NaN   NaN   NaN   NaN  \n",
       "2015                  NaN   NaN   NaN   NaN  \n",
       "2016                  NaN   NaN   NaN   NaN  \n",
       "2017                  NaN   NaN   NaN   NaN  \n",
       "2018                  NaN   NaN   NaN   NaN  \n",
       "2019                  1.0   NaN   NaN   NaN  \n",
       "2020                  NaN   1.0   NaN   NaN  \n",
       "2021                  NaN   NaN   1.0   NaN  \n",
       "2022                  NaN   NaN   NaN   1.0  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None) \n",
    "cor = all_X.corr()\n",
    "cor[cor>00.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1c4656b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_X, data_y, distillation=False):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.data_X = data_X\n",
    "        self.data_y = data_y\n",
    "        self.distillation = distillation\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.distillation:\n",
    "            # 지식 증류 학습 시\n",
    "            teacher_X = torch.Tensor(self.data_X.iloc[index].values)\n",
    "            student_X = torch.Tensor(self.data_X[test_stage_features].iloc[index].values)\n",
    "            y = self.data_y.values[index]\n",
    "            return teacher_X, student_X, y\n",
    "        else:\n",
    "            if self.data_y is None:\n",
    "                test_X = torch.Tensor(self.data_X.iloc[index].values)\n",
    "                return test_X\n",
    "            else:\n",
    "                teacher_X = torch.Tensor(self.data_X.iloc[index].values)\n",
    "                y = self.data_y.values[index]\n",
    "                return teacher_X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b83c4d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_X, train_y, False)\n",
    "val_dataset = CustomDataset(val_X, val_y, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7d4b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7fd4bab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANONYMOUS_1</th>\n",
       "      <th>SAMPLE_TRANSFER_DAY</th>\n",
       "      <th>ANONYMOUS_2</th>\n",
       "      <th>AG</th>\n",
       "      <th>AL</th>\n",
       "      <th>B</th>\n",
       "      <th>BA</th>\n",
       "      <th>BE</th>\n",
       "      <th>CA</th>\n",
       "      <th>CD</th>\n",
       "      <th>CO</th>\n",
       "      <th>CR</th>\n",
       "      <th>CU</th>\n",
       "      <th>FH2O</th>\n",
       "      <th>FNOX</th>\n",
       "      <th>FOPTIMETHGLY</th>\n",
       "      <th>FOXID</th>\n",
       "      <th>FSO4</th>\n",
       "      <th>FTBN</th>\n",
       "      <th>FE</th>\n",
       "      <th>FUEL</th>\n",
       "      <th>H2O</th>\n",
       "      <th>K</th>\n",
       "      <th>LI</th>\n",
       "      <th>MG</th>\n",
       "      <th>MN</th>\n",
       "      <th>MO</th>\n",
       "      <th>NA</th>\n",
       "      <th>NI</th>\n",
       "      <th>P</th>\n",
       "      <th>PB</th>\n",
       "      <th>PQINDEX</th>\n",
       "      <th>S</th>\n",
       "      <th>SB</th>\n",
       "      <th>SI</th>\n",
       "      <th>SN</th>\n",
       "      <th>SOOTPERCENTAGE</th>\n",
       "      <th>TI</th>\n",
       "      <th>U100</th>\n",
       "      <th>U75</th>\n",
       "      <th>U50</th>\n",
       "      <th>U25</th>\n",
       "      <th>U20</th>\n",
       "      <th>U14</th>\n",
       "      <th>U6</th>\n",
       "      <th>U4</th>\n",
       "      <th>V</th>\n",
       "      <th>V100</th>\n",
       "      <th>V40</th>\n",
       "      <th>ZN</th>\n",
       "      <th>COMPONENT1</th>\n",
       "      <th>COMPONENT2</th>\n",
       "      <th>COMPONENT3</th>\n",
       "      <th>COMPONENT4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>-0.069099</td>\n",
       "      <td>0.116588</td>\n",
       "      <td>-0.337936</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.101686</td>\n",
       "      <td>0.678118</td>\n",
       "      <td>-0.228777</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>1.220967</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.113358</td>\n",
       "      <td>-0.261477</td>\n",
       "      <td>-0.359401</td>\n",
       "      <td>-0.589503</td>\n",
       "      <td>-0.355339</td>\n",
       "      <td>-0.585942</td>\n",
       "      <td>-0.605969</td>\n",
       "      <td>-0.607530</td>\n",
       "      <td>-0.314001</td>\n",
       "      <td>-0.108366</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.198039</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>-0.270107</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>-0.398820</td>\n",
       "      <td>-0.208246</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>-1.043886</td>\n",
       "      <td>-0.154584</td>\n",
       "      <td>-0.263715</td>\n",
       "      <td>-1.105093</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.175244</td>\n",
       "      <td>0.783891</td>\n",
       "      <td>-0.383867</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.074288</td>\n",
       "      <td>-0.097581</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>-0.045480</td>\n",
       "      <td>0.012590</td>\n",
       "      <td>0.149684</td>\n",
       "      <td>0.263073</td>\n",
       "      <td>0.501173</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>-0.595864</td>\n",
       "      <td>-0.755923</td>\n",
       "      <td>-0.284106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>-0.413153</td>\n",
       "      <td>-0.225434</td>\n",
       "      <td>0.293370</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.125019</td>\n",
       "      <td>-0.549336</td>\n",
       "      <td>0.102931</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>-0.780446</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.043191</td>\n",
       "      <td>-0.214906</td>\n",
       "      <td>1.081328</td>\n",
       "      <td>2.093840</td>\n",
       "      <td>2.074501</td>\n",
       "      <td>1.955765</td>\n",
       "      <td>1.988312</td>\n",
       "      <td>2.120598</td>\n",
       "      <td>-0.283485</td>\n",
       "      <td>-0.108366</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>0.750812</td>\n",
       "      <td>0.32653</td>\n",
       "      <td>-0.182968</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>1.918859</td>\n",
       "      <td>-0.208246</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>0.066496</td>\n",
       "      <td>-0.154584</td>\n",
       "      <td>-0.259153</td>\n",
       "      <td>-0.625465</td>\n",
       "      <td>0.617902</td>\n",
       "      <td>-0.131071</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>1.870671</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.074288</td>\n",
       "      <td>-0.097581</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>-0.116766</td>\n",
       "      <td>-0.116814</td>\n",
       "      <td>-0.128980</td>\n",
       "      <td>-0.122101</td>\n",
       "      <td>-0.170889</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>1.798817</td>\n",
       "      <td>0.083483</td>\n",
       "      <td>1.384500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>-0.413435</td>\n",
       "      <td>-0.396445</td>\n",
       "      <td>-0.013264</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.113352</td>\n",
       "      <td>0.127214</td>\n",
       "      <td>-0.228777</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>1.283110</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.113358</td>\n",
       "      <td>-0.253715</td>\n",
       "      <td>0.488087</td>\n",
       "      <td>0.901243</td>\n",
       "      <td>-0.355339</td>\n",
       "      <td>0.939082</td>\n",
       "      <td>1.231647</td>\n",
       "      <td>1.795225</td>\n",
       "      <td>-0.314001</td>\n",
       "      <td>2.083448</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.008269</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>-0.148112</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>0.168094</td>\n",
       "      <td>-0.208246</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>-0.006345</td>\n",
       "      <td>-0.061985</td>\n",
       "      <td>-0.266974</td>\n",
       "      <td>-1.003650</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.150703</td>\n",
       "      <td>-0.332775</td>\n",
       "      <td>-0.158414</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.074288</td>\n",
       "      <td>-0.097581</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>-0.116766</td>\n",
       "      <td>-0.116814</td>\n",
       "      <td>-0.128980</td>\n",
       "      <td>-0.122101</td>\n",
       "      <td>-0.170889</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>1.649149</td>\n",
       "      <td>-0.114024</td>\n",
       "      <td>0.801991</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12302</th>\n",
       "      <td>-0.003954</td>\n",
       "      <td>-0.567456</td>\n",
       "      <td>-0.337936</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.125019</td>\n",
       "      <td>-0.597661</td>\n",
       "      <td>-0.228777</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>-0.906083</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.008108</td>\n",
       "      <td>-0.253715</td>\n",
       "      <td>-0.359401</td>\n",
       "      <td>-0.589503</td>\n",
       "      <td>-0.355339</td>\n",
       "      <td>-0.585942</td>\n",
       "      <td>-0.605969</td>\n",
       "      <td>-0.607530</td>\n",
       "      <td>1.540321</td>\n",
       "      <td>-0.108366</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.198039</td>\n",
       "      <td>0.32653</td>\n",
       "      <td>-0.182968</td>\n",
       "      <td>0.788237</td>\n",
       "      <td>-0.365472</td>\n",
       "      <td>-0.155563</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>0.913940</td>\n",
       "      <td>-0.154584</td>\n",
       "      <td>-0.058417</td>\n",
       "      <td>1.070625</td>\n",
       "      <td>1.019230</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>-0.332775</td>\n",
       "      <td>-0.383867</td>\n",
       "      <td>5.119013</td>\n",
       "      <td>-0.074288</td>\n",
       "      <td>-0.097581</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>-0.116766</td>\n",
       "      <td>-0.116814</td>\n",
       "      <td>-0.128980</td>\n",
       "      <td>-0.122101</td>\n",
       "      <td>-0.170889</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>-0.595864</td>\n",
       "      <td>0.891288</td>\n",
       "      <td>-0.998150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>-0.519754</td>\n",
       "      <td>-0.225434</td>\n",
       "      <td>-0.337936</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.055021</td>\n",
       "      <td>-0.587996</td>\n",
       "      <td>0.434638</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>-0.905408</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.078274</td>\n",
       "      <td>-0.230430</td>\n",
       "      <td>0.827082</td>\n",
       "      <td>1.199392</td>\n",
       "      <td>-0.355339</td>\n",
       "      <td>1.277977</td>\n",
       "      <td>1.339742</td>\n",
       "      <td>1.970426</td>\n",
       "      <td>-0.290665</td>\n",
       "      <td>-0.108366</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>0.118245</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>3.337463</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>2.185642</td>\n",
       "      <td>-0.050197</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>-0.036547</td>\n",
       "      <td>0.030615</td>\n",
       "      <td>-0.265019</td>\n",
       "      <td>-0.834578</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.135979</td>\n",
       "      <td>0.783891</td>\n",
       "      <td>-0.158414</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.074288</td>\n",
       "      <td>-0.097581</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>-0.116766</td>\n",
       "      <td>-0.116814</td>\n",
       "      <td>-0.128980</td>\n",
       "      <td>-0.122101</td>\n",
       "      <td>-0.170889</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>1.848706</td>\n",
       "      <td>0.231613</td>\n",
       "      <td>0.873395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10754</th>\n",
       "      <td>0.061190</td>\n",
       "      <td>-0.225434</td>\n",
       "      <td>-0.337936</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.113352</td>\n",
       "      <td>3.683932</td>\n",
       "      <td>-0.228777</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>1.568833</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.113358</td>\n",
       "      <td>-0.261477</td>\n",
       "      <td>1.250826</td>\n",
       "      <td>2.093840</td>\n",
       "      <td>-0.355339</td>\n",
       "      <td>2.125213</td>\n",
       "      <td>1.555932</td>\n",
       "      <td>1.670081</td>\n",
       "      <td>-0.306821</td>\n",
       "      <td>-0.108366</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.008269</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>-0.174254</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>3.819689</td>\n",
       "      <td>-0.050197</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>0.499989</td>\n",
       "      <td>-0.154584</td>\n",
       "      <td>-0.268929</td>\n",
       "      <td>-0.728626</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.145795</td>\n",
       "      <td>-0.332775</td>\n",
       "      <td>-0.158414</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.074288</td>\n",
       "      <td>-0.097581</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>-0.116766</td>\n",
       "      <td>-0.116814</td>\n",
       "      <td>-0.128980</td>\n",
       "      <td>-0.122101</td>\n",
       "      <td>-0.170889</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>1.765557</td>\n",
       "      <td>0.049907</td>\n",
       "      <td>1.497244</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11793</th>\n",
       "      <td>-0.406103</td>\n",
       "      <td>-0.310939</td>\n",
       "      <td>-0.337936</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.113352</td>\n",
       "      <td>1.866913</td>\n",
       "      <td>-0.228777</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>1.208133</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.043191</td>\n",
       "      <td>-0.245953</td>\n",
       "      <td>1.166077</td>\n",
       "      <td>2.690139</td>\n",
       "      <td>2.074501</td>\n",
       "      <td>2.803001</td>\n",
       "      <td>2.096407</td>\n",
       "      <td>1.670081</td>\n",
       "      <td>-0.290665</td>\n",
       "      <td>-0.108366</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.008269</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>-0.182968</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>3.552906</td>\n",
       "      <td>-0.102880</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>0.384510</td>\n",
       "      <td>0.123214</td>\n",
       "      <td>-0.256546</td>\n",
       "      <td>-0.780367</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.145795</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>1.419763</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.074288</td>\n",
       "      <td>-0.097581</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>-0.116766</td>\n",
       "      <td>-0.116814</td>\n",
       "      <td>-0.128980</td>\n",
       "      <td>-0.122101</td>\n",
       "      <td>-0.170889</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>1.782187</td>\n",
       "      <td>0.032131</td>\n",
       "      <td>1.499123</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10052</th>\n",
       "      <td>0.304003</td>\n",
       "      <td>-0.396445</td>\n",
       "      <td>-0.337936</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.148351</td>\n",
       "      <td>-0.549336</td>\n",
       "      <td>-0.228777</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>-0.911487</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>0.026975</td>\n",
       "      <td>0.848467</td>\n",
       "      <td>-0.359401</td>\n",
       "      <td>-0.589503</td>\n",
       "      <td>-0.355339</td>\n",
       "      <td>-0.585942</td>\n",
       "      <td>-0.605969</td>\n",
       "      <td>-0.607530</td>\n",
       "      <td>0.034245</td>\n",
       "      <td>-0.108366</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>-0.134782</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>-0.261393</td>\n",
       "      <td>0.020479</td>\n",
       "      <td>-0.398820</td>\n",
       "      <td>-0.050197</td>\n",
       "      <td>1.391556</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>-0.154584</td>\n",
       "      <td>-0.193979</td>\n",
       "      <td>1.860381</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.150703</td>\n",
       "      <td>-0.332775</td>\n",
       "      <td>-0.383867</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.074288</td>\n",
       "      <td>-0.097581</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>-0.116766</td>\n",
       "      <td>-0.116814</td>\n",
       "      <td>-0.128980</td>\n",
       "      <td>-0.122101</td>\n",
       "      <td>-0.170889</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>-0.595864</td>\n",
       "      <td>0.707606</td>\n",
       "      <td>-0.868494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805</th>\n",
       "      <td>-0.553595</td>\n",
       "      <td>-0.396445</td>\n",
       "      <td>-0.007853</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.125019</td>\n",
       "      <td>-0.559001</td>\n",
       "      <td>0.766346</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>-0.178604</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.078274</td>\n",
       "      <td>0.064521</td>\n",
       "      <td>0.657585</td>\n",
       "      <td>0.901243</td>\n",
       "      <td>-0.355339</td>\n",
       "      <td>0.939082</td>\n",
       "      <td>1.015457</td>\n",
       "      <td>1.169508</td>\n",
       "      <td>-0.267329</td>\n",
       "      <td>2.083448</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>0.181501</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>7.938423</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>0.418203</td>\n",
       "      <td>-0.155563</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>0.285019</td>\n",
       "      <td>-0.154584</td>\n",
       "      <td>-0.265671</td>\n",
       "      <td>-0.920885</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.121254</td>\n",
       "      <td>0.783891</td>\n",
       "      <td>-0.383867</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.074288</td>\n",
       "      <td>-0.097581</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>-0.116766</td>\n",
       "      <td>-0.116814</td>\n",
       "      <td>-0.128980</td>\n",
       "      <td>-0.122101</td>\n",
       "      <td>-0.170889</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>1.582630</td>\n",
       "      <td>-0.416210</td>\n",
       "      <td>1.207868</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12169</th>\n",
       "      <td>0.428088</td>\n",
       "      <td>3.109281</td>\n",
       "      <td>0.293370</td>\n",
       "      <td>-0.151896</td>\n",
       "      <td>-0.101686</td>\n",
       "      <td>0.504148</td>\n",
       "      <td>0.102931</td>\n",
       "      <td>-0.042583</td>\n",
       "      <td>-0.862178</td>\n",
       "      <td>-0.06603</td>\n",
       "      <td>-0.087612</td>\n",
       "      <td>-0.113358</td>\n",
       "      <td>-0.245953</td>\n",
       "      <td>0.911831</td>\n",
       "      <td>1.497542</td>\n",
       "      <td>-0.355339</td>\n",
       "      <td>1.616871</td>\n",
       "      <td>1.772122</td>\n",
       "      <td>1.845282</td>\n",
       "      <td>-0.294255</td>\n",
       "      <td>-0.108366</td>\n",
       "      <td>-0.044504</td>\n",
       "      <td>0.244758</td>\n",
       "      <td>-0.10941</td>\n",
       "      <td>-0.139398</td>\n",
       "      <td>-0.235440</td>\n",
       "      <td>-0.398820</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>-0.189712</td>\n",
       "      <td>0.270807</td>\n",
       "      <td>0.030615</td>\n",
       "      <td>-0.265671</td>\n",
       "      <td>-0.107299</td>\n",
       "      <td>-0.184755</td>\n",
       "      <td>-0.150703</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>0.067040</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>-0.074288</td>\n",
       "      <td>-0.097581</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>-0.116766</td>\n",
       "      <td>-0.116814</td>\n",
       "      <td>-0.128980</td>\n",
       "      <td>-0.122101</td>\n",
       "      <td>-0.170889</td>\n",
       "      <td>-0.113111</td>\n",
       "      <td>1.748928</td>\n",
       "      <td>-0.159451</td>\n",
       "      <td>1.209747</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11276 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ANONYMOUS_1  SAMPLE_TRANSFER_DAY  ANONYMOUS_2        AG        AL  \\\n",
       "6224     -0.069099             0.116588    -0.337936 -0.151896 -0.101686   \n",
       "1786     -0.413153            -0.225434     0.293370 -0.151896 -0.125019   \n",
       "2999     -0.413435            -0.396445    -0.013264 -0.151896 -0.113352   \n",
       "12302    -0.003954            -0.567456    -0.337936 -0.151896 -0.125019   \n",
       "8063     -0.519754            -0.225434    -0.337936 -0.151896 -0.055021   \n",
       "...            ...                  ...          ...       ...       ...   \n",
       "10754     0.061190            -0.225434    -0.337936 -0.151896 -0.113352   \n",
       "11793    -0.406103            -0.310939    -0.337936 -0.151896 -0.113352   \n",
       "10052     0.304003            -0.396445    -0.337936 -0.151896 -0.148351   \n",
       "11805    -0.553595            -0.396445    -0.007853 -0.151896 -0.125019   \n",
       "12169     0.428088             3.109281     0.293370 -0.151896 -0.101686   \n",
       "\n",
       "              B        BA        BE        CA       CD        CO        CR  \\\n",
       "6224   0.678118 -0.228777 -0.042583  1.220967 -0.06603 -0.087612 -0.113358   \n",
       "1786  -0.549336  0.102931 -0.042583 -0.780446 -0.06603 -0.087612 -0.043191   \n",
       "2999   0.127214 -0.228777 -0.042583  1.283110 -0.06603 -0.087612 -0.113358   \n",
       "12302 -0.597661 -0.228777 -0.042583 -0.906083 -0.06603 -0.087612 -0.008108   \n",
       "8063  -0.587996  0.434638 -0.042583 -0.905408 -0.06603 -0.087612 -0.078274   \n",
       "...         ...       ...       ...       ...      ...       ...       ...   \n",
       "10754  3.683932 -0.228777 -0.042583  1.568833 -0.06603 -0.087612 -0.113358   \n",
       "11793  1.866913 -0.228777 -0.042583  1.208133 -0.06603 -0.087612 -0.043191   \n",
       "10052 -0.549336 -0.228777 -0.042583 -0.911487 -0.06603 -0.087612  0.026975   \n",
       "11805 -0.559001  0.766346 -0.042583 -0.178604 -0.06603 -0.087612 -0.078274   \n",
       "12169  0.504148  0.102931 -0.042583 -0.862178 -0.06603 -0.087612 -0.113358   \n",
       "\n",
       "             CU      FH2O      FNOX  FOPTIMETHGLY     FOXID      FSO4  \\\n",
       "6224  -0.261477 -0.359401 -0.589503     -0.355339 -0.585942 -0.605969   \n",
       "1786  -0.214906  1.081328  2.093840      2.074501  1.955765  1.988312   \n",
       "2999  -0.253715  0.488087  0.901243     -0.355339  0.939082  1.231647   \n",
       "12302 -0.253715 -0.359401 -0.589503     -0.355339 -0.585942 -0.605969   \n",
       "8063  -0.230430  0.827082  1.199392     -0.355339  1.277977  1.339742   \n",
       "...         ...       ...       ...           ...       ...       ...   \n",
       "10754 -0.261477  1.250826  2.093840     -0.355339  2.125213  1.555932   \n",
       "11793 -0.245953  1.166077  2.690139      2.074501  2.803001  2.096407   \n",
       "10052  0.848467 -0.359401 -0.589503     -0.355339 -0.585942 -0.605969   \n",
       "11805  0.064521  0.657585  0.901243     -0.355339  0.939082  1.015457   \n",
       "12169 -0.245953  0.911831  1.497542     -0.355339  1.616871  1.772122   \n",
       "\n",
       "           FTBN        FE      FUEL       H2O         K       LI        MG  \\\n",
       "6224  -0.607530 -0.314001 -0.108366 -0.044504 -0.198039 -0.10941 -0.270107   \n",
       "1786   2.120598 -0.283485 -0.108366 -0.044504  0.750812  0.32653 -0.182968   \n",
       "2999   1.795225 -0.314001  2.083448 -0.044504 -0.008269 -0.10941 -0.148112   \n",
       "12302 -0.607530  1.540321 -0.108366 -0.044504 -0.198039  0.32653 -0.182968   \n",
       "8063   1.970426 -0.290665 -0.108366 -0.044504  0.118245 -0.10941  3.337463   \n",
       "...         ...       ...       ...       ...       ...      ...       ...   \n",
       "10754  1.670081 -0.306821 -0.108366 -0.044504 -0.008269 -0.10941 -0.174254   \n",
       "11793  1.670081 -0.290665 -0.108366 -0.044504 -0.008269 -0.10941 -0.182968   \n",
       "10052 -0.607530  0.034245 -0.108366 -0.044504 -0.134782 -0.10941 -0.261393   \n",
       "11805  1.169508 -0.267329  2.083448 -0.044504  0.181501 -0.10941  7.938423   \n",
       "12169  1.845282 -0.294255 -0.108366 -0.044504  0.244758 -0.10941 -0.139398   \n",
       "\n",
       "             MN        MO        NA        NI         P        PB   PQINDEX  \\\n",
       "6224  -0.235440 -0.398820 -0.208246 -0.189712 -1.043886 -0.154584 -0.263715   \n",
       "1786  -0.235440  1.918859 -0.208246 -0.189712  0.066496 -0.154584 -0.259153   \n",
       "2999  -0.235440  0.168094 -0.208246 -0.189712 -0.006345 -0.061985 -0.266974   \n",
       "12302  0.788237 -0.365472 -0.155563 -0.189712  0.913940 -0.154584 -0.058417   \n",
       "8063  -0.235440  2.185642 -0.050197 -0.189712 -0.036547  0.030615 -0.265019   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10754 -0.235440  3.819689 -0.050197 -0.189712  0.499989 -0.154584 -0.268929   \n",
       "11793 -0.235440  3.552906 -0.102880 -0.189712  0.384510  0.123214 -0.256546   \n",
       "10052  0.020479 -0.398820 -0.050197  1.391556  0.029187 -0.154584 -0.193979   \n",
       "11805 -0.235440  0.418203 -0.155563 -0.189712  0.285019 -0.154584 -0.265671   \n",
       "12169 -0.235440 -0.398820  0.002486 -0.189712  0.270807  0.030615 -0.265671   \n",
       "\n",
       "              S        SB        SI        SN  SOOTPERCENTAGE        TI  \\\n",
       "6224  -1.105093 -0.184755 -0.175244  0.783891       -0.383867 -0.097491   \n",
       "1786  -0.625465  0.617902 -0.131071  0.039447        1.870671 -0.097491   \n",
       "2999  -1.003650 -0.184755 -0.150703 -0.332775       -0.158414 -0.097491   \n",
       "12302  1.070625  1.019230 -0.072173 -0.332775       -0.383867  5.119013   \n",
       "8063  -0.834578 -0.184755 -0.135979  0.783891       -0.158414 -0.097491   \n",
       "...         ...       ...       ...       ...             ...       ...   \n",
       "10754 -0.728626 -0.184755 -0.145795 -0.332775       -0.158414 -0.097491   \n",
       "11793 -0.780367 -0.184755 -0.145795  0.039447        1.419763 -0.097491   \n",
       "10052  1.860381 -0.184755 -0.150703 -0.332775       -0.383867 -0.097491   \n",
       "11805 -0.920885 -0.184755 -0.121254  0.783891       -0.383867 -0.097491   \n",
       "12169 -0.107299 -0.184755 -0.150703  0.039447        0.067040 -0.097491   \n",
       "\n",
       "           U100       U75       U50       U25       U20       U14        U6  \\\n",
       "6224  -0.074288 -0.097581 -0.070573 -0.045480  0.012590  0.149684  0.263073   \n",
       "1786  -0.074288 -0.097581 -0.070573 -0.116766 -0.116814 -0.128980 -0.122101   \n",
       "2999  -0.074288 -0.097581 -0.070573 -0.116766 -0.116814 -0.128980 -0.122101   \n",
       "12302 -0.074288 -0.097581 -0.070573 -0.116766 -0.116814 -0.128980 -0.122101   \n",
       "8063  -0.074288 -0.097581 -0.070573 -0.116766 -0.116814 -0.128980 -0.122101   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10754 -0.074288 -0.097581 -0.070573 -0.116766 -0.116814 -0.128980 -0.122101   \n",
       "11793 -0.074288 -0.097581 -0.070573 -0.116766 -0.116814 -0.128980 -0.122101   \n",
       "10052 -0.074288 -0.097581 -0.070573 -0.116766 -0.116814 -0.128980 -0.122101   \n",
       "11805 -0.074288 -0.097581 -0.070573 -0.116766 -0.116814 -0.128980 -0.122101   \n",
       "12169 -0.074288 -0.097581 -0.070573 -0.116766 -0.116814 -0.128980 -0.122101   \n",
       "\n",
       "             U4         V      V100       V40        ZN  COMPONENT1  \\\n",
       "6224   0.501173 -0.113111 -0.595864 -0.755923 -0.284106           0   \n",
       "1786  -0.170889 -0.113111  1.798817  0.083483  1.384500           1   \n",
       "2999  -0.170889 -0.113111  1.649149 -0.114024  0.801991           1   \n",
       "12302 -0.170889 -0.113111 -0.595864  0.891288 -0.998150           0   \n",
       "8063  -0.170889 -0.113111  1.848706  0.231613  0.873395           1   \n",
       "...         ...       ...       ...       ...       ...         ...   \n",
       "10754 -0.170889 -0.113111  1.765557  0.049907  1.497244           1   \n",
       "11793 -0.170889 -0.113111  1.782187  0.032131  1.499123           1   \n",
       "10052 -0.170889 -0.113111 -0.595864  0.707606 -0.868494           0   \n",
       "11805 -0.170889 -0.113111  1.582630 -0.416210  1.207868           1   \n",
       "12169 -0.170889 -0.113111  1.748928 -0.159451  1.209747           1   \n",
       "\n",
       "       COMPONENT2  COMPONENT3  COMPONENT4  \n",
       "6224            1           0           0  \n",
       "1786            0           0           0  \n",
       "2999            0           0           0  \n",
       "12302           0           1           0  \n",
       "8063            0           0           0  \n",
       "...           ...         ...         ...  \n",
       "10754           0           0           0  \n",
       "11793           0           0           0  \n",
       "10052           0           1           0  \n",
       "11805           0           0           0  \n",
       "12169           0           0           0  \n",
       "\n",
       "[11276 rows x 54 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "806cbd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Teacher, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=54, out_features=256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=256, out_features=1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=1024, out_features=4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=4096, out_features=1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=1024, out_features=256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=256, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "960b0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    for epoch in range(CFG[\"EPOCHS\"]):\n",
    "        train_loss = []\n",
    "  \n",
    "        model.train()\n",
    "        for X, y in tqdm(train_loader):\n",
    "            X = X.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_pred = model(X)\n",
    "            \n",
    "            loss = criterion(y_pred, y.reshape(-1, 1))\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        val_loss, val_score = validation_teacher(model, val_loader, criterion, device)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{np.mean(train_loss) :.5f}] Val Loss : [{np.mean(val_loss) :.5f}] Val F1 Score : [{val_score:.5f}]')\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_score)\n",
    "            \n",
    "        if best_score < val_score:\n",
    "            best_model = model\n",
    "            best_score = val_score\n",
    "        \n",
    "    return best_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9c51ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def competition_metric(true, pred):\n",
    "    return f1_score(true, pred, average=\"macro\")\n",
    "\n",
    "def validation_teacher(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = []\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    threshold = 0.35\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(val_loader):\n",
    "            X = X.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            model_pred = model(X.to(device))\n",
    "            \n",
    "            loss = criterion(model_pred, y.reshape(-1, 1))\n",
    "            val_loss.append(loss.item())      \n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')  \n",
    "            pred_labels += model_pred.tolist()\n",
    "            true_labels += y.tolist()\n",
    "        \n",
    "        pred_labels = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "        val_f1 = competition_metric(true_labels, pred_labels)\n",
    "    return val_loss, val_f1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e2d703e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50486491657a4a20af4d5c3e274858ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f190df646fb54c93aac72f2fc02cc703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.40143] Val Loss : [0.34407] Val F1 Score : [0.78184]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c442c23a2a14e7b9916c898fd7f6c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873d599486a84be48b5244d60b522114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.34531] Val Loss : [0.31065] Val F1 Score : [0.79345]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112efe63559949e092fa17e655e75673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7cda8c0e4443edaeba3db4ff8703f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.32751] Val Loss : [0.30431] Val F1 Score : [0.80480]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f392ee5f4ae143e585205b52dcada5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53317ab763274d3c8d814f159355e9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.34412] Val Loss : [0.34273] Val F1 Score : [0.79291]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcbd75c4c6d4828b309096f1587cfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93375f4d82564fedaf0cbbb611906bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.34162] Val Loss : [0.30081] Val F1 Score : [0.79981]\n",
      "Epoch 00005: reducing learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6fd6958ca740bb9dfcbdcc0548f15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb5b46bc64b48acbcc7d598169d5bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.31595] Val Loss : [0.29329] Val F1 Score : [0.80144]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669cbc95ff1b4c3799f2f95696b0506a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993b55cedc9b4bcebf64c7cc2b9c3fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.30897] Val Loss : [0.29170] Val F1 Score : [0.81253]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a53b1577e8420fa12cd4b4f892e312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9de1f9b4b3846c5b5980b963d5d2af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.30595] Val Loss : [0.29520] Val F1 Score : [0.80302]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b7884477014432a3ff9add2f9a4c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a2aad300704c03b8e97ba786e4c972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.29785] Val Loss : [0.29376] Val F1 Score : [0.81108]\n",
      "Epoch 00009: reducing learning rate of group 0 to 2.5000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ee7bea4298429b902a76d4dc7884f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26640e4def5d41d8a5d8a860a4f93b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.28841] Val Loss : [0.28651] Val F1 Score : [0.81183]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7950f7576274113aa1e74c2dad7df96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d34c94cb4249488342f0a9d99eb8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.27761] Val Loss : [0.28383] Val F1 Score : [0.81060]\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.2500e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2fc8f00a8e4e469888ffc2502ff1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ca2f0b3ed54cc29e42d9bcd64dd30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.29245] Val Loss : [0.28317] Val F1 Score : [0.81275]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b717d4c3a444ed9b724ba48fafb409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfaaa925a884db881d3b572586a18f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.27925] Val Loss : [0.28197] Val F1 Score : [0.81342]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ca2e613f2645e994d7d4a0edd004f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e305168eeb47f98d3a5d5f47b370a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.28500] Val Loss : [0.28138] Val F1 Score : [0.81425]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5d5251f30e45cfaa02ba489808fd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb965d95df1849258e549e203be85efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [0.27129] Val Loss : [0.28344] Val F1 Score : [0.81383]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4370d18aa3304dacbc985381c68b61b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb5de73a70a4adc83413a8195c668c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [0.26874] Val Loss : [0.29022] Val F1 Score : [0.81113]\n",
      "Epoch 00016: reducing learning rate of group 0 to 6.2500e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5d6aead0804229bfbbf042adb2517a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9059bdd746934876a0527e3d4697a7de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [0.26749] Val Loss : [0.27941] Val F1 Score : [0.81449]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482702b90905496abae5179a0a242680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3cf762f144f48bba01c5ce05e4b9c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [0.27454] Val Loss : [0.28473] Val F1 Score : [0.81219]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a2539dae774c26b23d948ca56749f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a159f2258c094b1ea15575abcb24c11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [0.27263] Val Loss : [0.28229] Val F1 Score : [0.81425]\n",
      "Epoch 00019: reducing learning rate of group 0 to 3.1250e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ef692a4d2b4ffcb566665234fb3df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c060ca6c8261449c8ccaa638abda4a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [0.26645] Val Loss : [0.28495] Val F1 Score : [0.81545]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ab9c34a6fd4c5c96d35b7e664cef38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513fe35303ab423c8713eed01f07f854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [0.26126] Val Loss : [0.28077] Val F1 Score : [0.81236]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044cc81e97054712b3e29bdb83af940b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee4057f854646199f78f769ee591d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Train Loss : [0.27065] Val Loss : [0.27976] Val F1 Score : [0.81389]\n",
      "Epoch 00022: reducing learning rate of group 0 to 1.5625e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d77e5a35f8a489a80769fac393c9bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3a4b751298420f8ec9b8c50bb05cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Train Loss : [0.26049] Val Loss : [0.29058] Val F1 Score : [0.79965]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e69ab0f9b84312b322aa07440af518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0bc54c6f3341dea72eedfc2db8499a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Train Loss : [0.27538] Val Loss : [0.28451] Val F1 Score : [0.81226]\n",
      "Epoch 00024: reducing learning rate of group 0 to 7.8125e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b79f24576ae49ac9d34eabdad658e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c421b669cbb4b8ba86aa7a1c998577a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Train Loss : [0.27172] Val Loss : [0.27694] Val F1 Score : [0.81280]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdf107090864e4abce9e45de1133a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ece8fb02f5431d88438479ed794fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Train Loss : [0.28419] Val Loss : [0.27932] Val F1 Score : [0.81024]\n",
      "Epoch 00026: reducing learning rate of group 0 to 3.9063e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af1b2a12d4f4a21a7c757de9c1cefcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a67298e790744799183db7ca21cc7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Train Loss : [0.25961] Val Loss : [0.28313] Val F1 Score : [0.81416]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5abcfd418a048d9957e60d98d89e361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fae271b01d4c00b782bab7a674e258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Train Loss : [0.26414] Val Loss : [0.28030] Val F1 Score : [0.80910]\n",
      "Epoch 00028: reducing learning rate of group 0 to 1.9531e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c06420452b455b87ec0988d5976218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8b49cf442349d4afddb3b6bcdc2e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Train Loss : [0.26979] Val Loss : [0.27737] Val F1 Score : [0.81204]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4069269ffc784f26bebae0c4e58301f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75591ba542142b6b89ec1e409d36f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Train Loss : [0.26697] Val Loss : [0.28106] Val F1 Score : [0.81126]\n",
      "Epoch 00030: reducing learning rate of group 0 to 9.7656e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37be727de0644d4b23b69fea6819b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f2861503124492800f722c66d43840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30], Train Loss : [0.27055] Val Loss : [0.28620] Val F1 Score : [0.80474]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075a7cc6bd6648f4a8fced16bf3c942f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0525f81d85ae48c0979d0db28c790cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], Train Loss : [0.26168] Val Loss : [0.28529] Val F1 Score : [0.81162]\n",
      "Epoch 00032: reducing learning rate of group 0 to 4.8828e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f77323114814fc4a978b576f07afb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9530431e1d840a9a0a982cbe55b9296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32], Train Loss : [0.27633] Val Loss : [0.27810] Val F1 Score : [0.81461]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc4c4eb30274bc89fe7977133df776c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4d22f729b748e9a74eec52efbabba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33], Train Loss : [0.26164] Val Loss : [0.28212] Val F1 Score : [0.81362]\n",
      "Epoch 00034: reducing learning rate of group 0 to 2.4414e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ecb5f480e64b42b3c8ec242bf4d847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95893ad8eda4775a5dc794552c2e933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34], Train Loss : [0.26213] Val Loss : [0.28947] Val F1 Score : [0.79661]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e6dae519794051967501981b829047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67901153d40b4e9ebf1a06cfd8ab7e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35], Train Loss : [0.28742] Val Loss : [0.27790] Val F1 Score : [0.81343]\n",
      "Epoch 00036: reducing learning rate of group 0 to 1.2207e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b15337828fd49818b7e997ae3b1d7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd078f37374419bb2aab72f2a45fc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36], Train Loss : [0.25934] Val Loss : [0.27945] Val F1 Score : [0.81100]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f152c367c2d74600b047c653d69824c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84df4335b0b74c259851878d55fdabd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37], Train Loss : [0.26099] Val Loss : [0.28155] Val F1 Score : [0.81196]\n",
      "Epoch 00038: reducing learning rate of group 0 to 6.1035e-07.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca4ef294d7d408e9851fd1061b541da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cc3a56e07f4775afe671a72c0cd185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38], Train Loss : [0.26178] Val Loss : [0.28817] Val F1 Score : [0.80828]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec44de26e3f74d64b9a81cb1dca0f9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd971742201b4f99a92a34edca951273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39], Train Loss : [0.27573] Val Loss : [0.27931] Val F1 Score : [0.81181]\n",
      "Epoch 00040: reducing learning rate of group 0 to 3.0518e-07.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07123ab44a0f4fe2819be148e77660c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae621eb92d624531b28f6f6133db08e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40], Train Loss : [0.26719] Val Loss : [0.28162] Val F1 Score : [0.81094]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e7f6e2b7c3489e836782d6a8dbcf04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18302aaabb1043a3960a5a2a3024abd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41], Train Loss : [0.26154] Val Loss : [0.27740] Val F1 Score : [0.81599]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b48569e3d82470b898e5247dbcd3806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fc28eac6e74cf5bd615ca182b491a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42], Train Loss : [0.27375] Val Loss : [0.28289] Val F1 Score : [0.81043]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e521c63e3ab94d1992bb39fac2802843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e847ec7c6e944b44aa27611f9fd644e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43], Train Loss : [0.26932] Val Loss : [0.28077] Val F1 Score : [0.81389]\n",
      "Epoch 00044: reducing learning rate of group 0 to 1.5259e-07.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67542891261b4a1c91cb01631465bc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d20b63b7ac483b92d5b08431e5538b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44], Train Loss : [0.25962] Val Loss : [0.28053] Val F1 Score : [0.81127]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bc5b4063304cdfaa661428f28af1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3a4825c1d14739a3fd304ad9e84bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45], Train Loss : [0.26926] Val Loss : [0.28113] Val F1 Score : [0.81042]\n",
      "Epoch 00046: reducing learning rate of group 0 to 7.6294e-08.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4fa6ae4b9948cfa1e8c207169a1f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07613cd452e4a668f13efc18a08e994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46], Train Loss : [0.26492] Val Loss : [0.27805] Val F1 Score : [0.81024]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfbe18322544b6c9b84f8961745603f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7b5de70aa349068991a7fcd2423bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47], Train Loss : [0.26622] Val Loss : [0.27987] Val F1 Score : [0.81367]\n",
      "Epoch 00048: reducing learning rate of group 0 to 3.8147e-08.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc949909340e451cae64e5b1870caedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef03b0ef7fe4f11a7292bbc5cc7f9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48], Train Loss : [0.27147] Val Loss : [0.28468] Val F1 Score : [0.81067]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b947a1f80bc84873bb2ce764d4aa575e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9dab74bf4445a5a36f9be8f0ad9d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49], Train Loss : [0.26592] Val Loss : [0.28313] Val F1 Score : [0.81089]\n",
      "Epoch 00050: reducing learning rate of group 0 to 1.9073e-08.\n"
     ]
    }
   ],
   "source": [
    "model = Teacher()\n",
    "model.eval()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "teacher_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e7ca8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Student, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=20, out_features=128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=128, out_features=512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=512, out_features=1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=512, out_features=128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=128, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1f0ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation(student_logits, labels, teacher_logits, alpha):\n",
    "    distillation_loss = nn.BCELoss()(student_logits, teacher_logits)\n",
    "    student_loss = nn.BCELoss()(student_logits, labels.reshape(-1, 1))\n",
    "    return alpha * student_loss + (1-alpha) * distillation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62c7fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distill_loss(output, target, teacher_output, loss_fn=distillation, opt=optimizer):\n",
    "    loss_b = loss_fn(output, target, teacher_output, alpha=0.1)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss_b.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss_b.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "81903967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_train(s_model, t_model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    s_model.to(device)\n",
    "    t_model.to(device)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(CFG[\"EPOCHS\"]):\n",
    "        train_loss = []\n",
    "        s_model.train()\n",
    "        t_model.eval()\n",
    "        \n",
    "        for X_t, X_s, y in tqdm(train_loader):\n",
    "            X_t = X_t.float().to(device)\n",
    "            X_s = X_s.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = s_model(X_s)\n",
    "            with torch.no_grad():\n",
    "                teacher_output = t_model(X_t)\n",
    "                \n",
    "            loss_b = distill_loss(output, y, teacher_output, loss_fn=distillation, opt=optimizer)\n",
    "\n",
    "            train_loss.append(loss_b)\n",
    "\n",
    "        val_loss, val_score = validation_student(s_model, t_model, val_loader, distill_loss, device)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{np.mean(train_loss) :.5f}] Val Loss : [{np.mean(val_loss) :.5f}] Val F1 Score : [{val_score:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_score)\n",
    "            \n",
    "        if best_score < val_score:\n",
    "            best_model = s_model\n",
    "            best_score = val_score\n",
    "        \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "224970c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_student(s_model, t_model, val_loader, criterion, device):\n",
    "    s_model.eval()\n",
    "    t_model.eval()\n",
    "\n",
    "    val_loss = []\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    threshold = 0.35\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_t, X_s, y in tqdm(val_loader):\n",
    "            X_t = X_t.float().to(device)\n",
    "            X_s = X_s.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            model_pred = s_model(X_s)\n",
    "            teacher_output = t_model(X_t)\n",
    "            \n",
    "            loss_b = distill_loss(model_pred, y, teacher_output, loss_fn=distillation, opt=None)\n",
    "            val_loss.append(loss_b)\n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            pred_labels += model_pred.tolist()\n",
    "            true_labels += y.tolist()\n",
    "        \n",
    "        pred_labels = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "        val_f1 = competition_metric(true_labels, pred_labels)\n",
    "    return val_loss, val_f1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8eba2184",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_X, train_y, True)\n",
    "val_dataset = CustomDataset(val_X, val_y, True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "91c19ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586086d53df9470d9bad47a16974e758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8079f8eae146a3b396852699149589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.38700] Val Loss : [0.36508] Val F1 Score : [0.76516]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed8df2b52494667b66c80ef3aaf39a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae692c9f4414457d8487d6d446531c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.34850] Val Loss : [0.34418] Val F1 Score : [0.77999]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec0c0d18a4447019b02efebc3db1ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f22964be8b247bbae7196c3d82ce2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.33948] Val Loss : [0.34067] Val F1 Score : [0.78268]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3630e7c38eb244a8955fa06303fe74c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0557d4749952492badde64d89d771bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.34044] Val Loss : [0.34084] Val F1 Score : [0.78537]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e415c2a02a047b39f31923fe8f82942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e516782d5b04f439449381b7e0357f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.34360] Val Loss : [0.34358] Val F1 Score : [0.78654]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1dfdfefdc445a097d69cf31d63a8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab38e3ef2894ebf95e63a36fbb7ec16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.33847] Val Loss : [0.34562] Val F1 Score : [0.78345]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8466a84a2644fa591de4a927775d4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2794bf812d042be8d0d7ba9e24e2306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.33196] Val Loss : [0.33928] Val F1 Score : [0.78189]\n",
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e07a8f1f6d44ba994645ea42b0d4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d79bc3ca6804d1f93ce2e0258c88cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.32682] Val Loss : [0.33427] Val F1 Score : [0.79477]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6d32cc2f6642d6a428c17a92318ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe36aa222879492f836d28cc7d290d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.32381] Val Loss : [0.33564] Val F1 Score : [0.78352]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4882506508404e879d2a27161fd990fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7678b9b97f0343f4a0393d02cced2f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.32080] Val Loss : [0.33295] Val F1 Score : [0.79498]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33280ad1186a4350bf1b6df8248d76c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60048b491ca24ddc8808b62d17f0a87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.31966] Val Loss : [0.33361] Val F1 Score : [0.79240]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98319103d81d4361aefdba8c768c9e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4285df45e634a5bb4ad8259089b1f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.32330] Val Loss : [0.33716] Val F1 Score : [0.79091]\n",
      "Epoch 00012: reducing learning rate of group 0 to 2.5000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6a088c5c5547c4ba42c5a52cb9cec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdae250adfc44d648206c9d658516e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.31993] Val Loss : [0.34003] Val F1 Score : [0.79731]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08237f9fa439462c84b8e95a5ab92332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d42ab0ff4943e39781f35acb88da32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.32418] Val Loss : [0.33922] Val F1 Score : [0.79412]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e66d4d24d1489b8092456ec607f0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44bfc62ac1bf479b95a5c16444f509c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [0.32067] Val Loss : [0.33376] Val F1 Score : [0.79616]\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.2500e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64810ac1c31a481c85b5323910745dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffad596c64f4e5794d9fb64cb5a3357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [0.31805] Val Loss : [0.35004] Val F1 Score : [0.80167]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703ecf9dbe3a41a9b358c5d6f9d0e359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53955bb515540c981024de26bb467e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [0.32096] Val Loss : [0.33502] Val F1 Score : [0.80147]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cce521290b24b3ba79a3e2d667c4eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f1c46c14a34a21ad067bf28d765b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [0.31474] Val Loss : [0.33131] Val F1 Score : [0.79325]\n",
      "Epoch 00018: reducing learning rate of group 0 to 6.2500e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780dddf77d744881a68019aef3b8e337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f448d9f99b4bd0b4202e54d0210e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [0.32084] Val Loss : [0.34317] Val F1 Score : [0.79964]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a166c2643824b4c9d2468bd712600e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c6a655f5c246a7920d25e094d694d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [0.31759] Val Loss : [0.34189] Val F1 Score : [0.79918]\n",
      "Epoch 00020: reducing learning rate of group 0 to 3.1250e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84c3f394d7a4fbdb917539459f9886d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2d9c53d7154305a866a6511e47c642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [0.31631] Val Loss : [0.33728] Val F1 Score : [0.79877]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19445ddcdcc4bbbae04618f62a69928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36814127255e4ff08b0731abf513842d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Train Loss : [0.31991] Val Loss : [0.34434] Val F1 Score : [0.80231]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0829c235db14e80b4d10ea4472627e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbd63e2c0534f9ba8f4bb48a047bd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Train Loss : [0.31825] Val Loss : [0.34207] Val F1 Score : [0.79861]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e312c2b7bd64b10a55c017736fa7b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47aadf63f00644b38d11895aa9762ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Train Loss : [0.32010] Val Loss : [0.33446] Val F1 Score : [0.79975]\n",
      "Epoch 00024: reducing learning rate of group 0 to 1.5625e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c901c19444094557a69712dd348f2b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7c6d55373246cfa5407011f5fd7f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Train Loss : [0.31534] Val Loss : [0.32908] Val F1 Score : [0.79129]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eeccb7247bf44d3a3243e431db9b731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07390002caad4a23acc26a613c6a5dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Train Loss : [0.31646] Val Loss : [0.33179] Val F1 Score : [0.79610]\n",
      "Epoch 00026: reducing learning rate of group 0 to 7.8125e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a6f842345045d5866c618cb1752a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef04f3127d8c4b8ea0146c730e596509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Train Loss : [0.31849] Val Loss : [0.33070] Val F1 Score : [0.80147]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a544630a5e354399b4f8c5c9b1ab77ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3e9dbdd3464cd88dd1d12c2e5d89f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Train Loss : [0.31401] Val Loss : [0.33249] Val F1 Score : [0.79564]\n",
      "Epoch 00028: reducing learning rate of group 0 to 3.9063e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6728874e83c4478b85c72ffbf2de869f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ca210043d7486f836558652a06a6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Train Loss : [0.31528] Val Loss : [0.33643] Val F1 Score : [0.79788]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85e6a6f800d4eecadb41632123781aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b10ff5cd63431dbec96be2e757db5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Train Loss : [0.31849] Val Loss : [0.33713] Val F1 Score : [0.79890]\n",
      "Epoch 00030: reducing learning rate of group 0 to 1.9531e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b92eec541243c89997db57c2203aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea1de4de5c94f7cabbc754092e980bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30], Train Loss : [0.31637] Val Loss : [0.34516] Val F1 Score : [0.79990]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b5cbf8901f46c1b15d793e7d6a6312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e4080148434f1d88ffeb4136669725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31], Train Loss : [0.31853] Val Loss : [0.34554] Val F1 Score : [0.79909]\n",
      "Epoch 00032: reducing learning rate of group 0 to 9.7656e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ea369b8ada4bc8a1b6e40abb5ee1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1d1b3d5c5142c3b2ce909b1c51a33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32], Train Loss : [0.31868] Val Loss : [0.33239] Val F1 Score : [0.79947]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941dac8267fa49619ae9b1d6cb0382df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4841cf6ae64df8bb4bbe7005f4f291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33], Train Loss : [0.31660] Val Loss : [0.35531] Val F1 Score : [0.80007]\n",
      "Epoch 00034: reducing learning rate of group 0 to 4.8828e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ed651bb5294945930130800b8d04f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd70aea3e1b44aa8882bd351ab140125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34], Train Loss : [0.31873] Val Loss : [0.32979] Val F1 Score : [0.79869]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c7e5818c9245219397df4f340885fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ff44d788c74c6f8a84ca27a1524e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35], Train Loss : [0.31906] Val Loss : [0.33080] Val F1 Score : [0.79647]\n",
      "Epoch 00036: reducing learning rate of group 0 to 2.4414e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ce0ed652e54e9a987d21219414869c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafe453baf70426d855071947519180b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36], Train Loss : [0.32352] Val Loss : [0.33183] Val F1 Score : [0.79493]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f6b1db7a8d41999b1829fdb53cd16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d83bfe6ce294c7c8734590d76a7a685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37], Train Loss : [0.32396] Val Loss : [0.34489] Val F1 Score : [0.80110]\n",
      "Epoch 00038: reducing learning rate of group 0 to 1.2207e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062fefec5f4f4640b5a0b2f76ec813f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457a8173a5384d31995a5c3fdf3b7121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38], Train Loss : [0.31447] Val Loss : [0.32814] Val F1 Score : [0.79723]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc4e27697174360a8fbfff22ba3be50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145f06211846415185d157a770a15834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39], Train Loss : [0.31814] Val Loss : [0.33182] Val F1 Score : [0.79931]\n",
      "Epoch 00040: reducing learning rate of group 0 to 6.1035e-07.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd802f7cd3d94dbeae2c1caa25fa3d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2025364cd74b1aa753342eb4d19c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40], Train Loss : [0.31615] Val Loss : [0.34872] Val F1 Score : [0.79699]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4911250be8d84065b1eff094dcbe6922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53739df68874bc29bb6a2dbeabd7437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41], Train Loss : [0.31482] Val Loss : [0.33049] Val F1 Score : [0.79568]\n",
      "Epoch 00042: reducing learning rate of group 0 to 3.0518e-07.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3dfd0a01f814c7baa1cc308a20629d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b8c89c2ca5424686f20fb30cae6a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42], Train Loss : [0.31969] Val Loss : [0.34625] Val F1 Score : [0.79836]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab8670fbf7642bb9d9dc659dc518577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cc332419b14f3cbf124a4d3931394d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43], Train Loss : [0.31709] Val Loss : [0.34704] Val F1 Score : [0.79893]\n",
      "Epoch 00044: reducing learning rate of group 0 to 1.5259e-07.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e805c99df448a3ac820896cb864015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6a97db15fa4dacaca820ad5b571d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44], Train Loss : [0.32993] Val Loss : [0.33767] Val F1 Score : [0.79012]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17b6f65034c442e8070c15368c82bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206997f5c29b4357893dc8be91f5f1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45], Train Loss : [0.31613] Val Loss : [0.33089] Val F1 Score : [0.79699]\n",
      "Epoch 00046: reducing learning rate of group 0 to 7.6294e-08.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff689d2f8f7400a84ad09deadac993a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1788a080c52241c6b94a7f9f963e294d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46], Train Loss : [0.31517] Val Loss : [0.33192] Val F1 Score : [0.79404]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc781dfe8a004a778275aa70bf6f9c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4794953049b64b6fa0a454da46323fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47], Train Loss : [0.31504] Val Loss : [0.32961] Val F1 Score : [0.79146]\n",
      "Epoch 00048: reducing learning rate of group 0 to 3.8147e-08.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59de82a4c36b4fdea4cb885f6d6daff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4322034111e4ea0896ce23e21a1ad96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48], Train Loss : [0.31455] Val Loss : [0.34517] Val F1 Score : [0.79916]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81512ac030bf475c8eea9a20559e6d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372fc793655741bc9597c514f1fa05ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49], Train Loss : [0.31570] Val Loss : [0.35041] Val F1 Score : [0.79826]\n",
      "Epoch 00050: reducing learning rate of group 0 to 1.9073e-08.\n"
     ]
    }
   ],
   "source": [
    "student_model = Student()\n",
    "student_model.eval()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "best_student_model = student_train(student_model, teacher_model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0044be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_threshold(model, val_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    thresholds = list(np.array(range(10, 51))/100) #[0.1, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    \n",
    "    best_score = 0\n",
    "    best_thr = None\n",
    "    with torch.no_grad():\n",
    "        for _, x_s, y in tqdm(iter(val_loader)):\n",
    "            x_s = x_s.float().to(device)\n",
    "            y = y.float().to(device)\n",
    "            \n",
    "            model_pred = model(x_s)\n",
    "            \n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            pred_labels += model_pred.tolist()\n",
    "            true_labels += y.tolist()\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            pred_labels_thr = np.where(np.array(pred_labels) > threshold, 1, 0)\n",
    "            score_thr = competition_metric(true_labels, pred_labels_thr)\n",
    "            if best_score < score_thr:\n",
    "                best_score = score_thr\n",
    "                best_thr = threshold\n",
    "    return best_thr, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "37b53473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7111d2656ef4441cbacd843a73890469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold : [0.4], Score : [0.79952]\n"
     ]
    }
   ],
   "source": [
    "best_threshold, best_score = choose_threshold(best_student_model, val_loader, device)\n",
    "print(f'Best Threshold : [{best_threshold}], Score : [{best_score:.5f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9cd9027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets = CustomDataset(test, None, False)\n",
    "test_loaders = DataLoader(test_datasets, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8e4fb07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, threshold, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    test_predict = []\n",
    "    with torch.no_grad():\n",
    "        for x in tqdm(test_loader):\n",
    "            x = x.float().to(device)\n",
    "            model_pred = model(x)\n",
    "\n",
    "            model_pred = model_pred.squeeze(1).to('cpu')\n",
    "            test_predict += model_pred\n",
    "        \n",
    "    test_predict = np.where(np.array(test_predict) > threshold, 1, 0)\n",
    "    print('Done.')\n",
    "    return test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b5dd4bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe3b54453e74b43b024c97fb3167048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "preds = inference(best_student_model, test_loaders, best_threshold, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b92c42b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Y_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Y_LABEL\n",
       "0  TEST_0000        0\n",
       "1  TEST_0001        0\n",
       "2  TEST_0002        0\n",
       "3  TEST_0003        0\n",
       "4  TEST_0004        0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['Y_LABEL'] = preds\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "59e9dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./submit_baseline_onehot_epoch50_dropout_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8116804e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc6844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66adb484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26993a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0879db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e66cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec381d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
